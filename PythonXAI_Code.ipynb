{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPijP+cQJy5yWgmgkPLJaq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alisafaa12/MoBShield/blob/main/PythonXAI_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "VuI1bPy_Xpi5",
        "outputId": "27db843a-bb9a-4ecb-dff9-88eb035bf010"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0b2959cf3d45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import plotly.graph_objects as go\n",
        "import plotly_express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve,auc\n",
        "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,confusion_matrix,classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import streamlit.components.v1 as components\n",
        "# Load our pkgs\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "import random\n",
        "import eli5\n",
        "from eli5 import show_weights\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from eli5 import show_prediction\n",
        "from eli5.sklearn import explain_decision_tree\n",
        "from eli5.sklearn import explain_weights_sklearn\n",
        "# run block of code and catch warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\t# execute code that will generate warnings\n",
        "\n",
        "def st_shap(plot, height=None):\n",
        "    shap_html = f\"<head>{shap.getjs()}</head><body>{plot.html()}</body>\"\n",
        "    background = \"<style>:root {background-color: white;}</style>\"\n",
        "    #components.html(yellow_background + html_content)\n",
        "    components.html(background+shap_html, height=height)\n",
        "#---------------------------------#\n",
        "# Page layout\n",
        "## Page expands to full width\n",
        "st.set_page_config(page_title='The Machine Learning App',\n",
        "    layout='wide')\n",
        "\n",
        "def plot(df,Y):\n",
        "    st.subheader('*Data Description*')\n",
        "    st.write(df.describe())\n",
        "    st.subheader('*Data Correlation*')\n",
        "\n",
        "    corr = df.corr(method ='pearson')\n",
        "    fig_corr = plt.figure(figsize=(12, 4))\n",
        "    sns.heatmap(corr)\n",
        "    st.pyplot(fig_corr)\n",
        "    st.subheader('*Data presentation*')\n",
        "    fig_desc = sns.pairplot(df, hue=Y.name)\n",
        "    st.pyplot(fig_desc)\n",
        "    Scatterplot(df,Y)\n",
        "#---------------------------------#\n",
        "# Model building\n",
        "@st.cache(suppress_st_warning=True)\n",
        "def build_model(df,target,model):\n",
        "    # create label encoder object\n",
        "\n",
        "    if target=='':\n",
        "        X = df.iloc[ : , :-1]\n",
        "        Y = df.iloc[ : , -1]\n",
        "    else:\n",
        "\n",
        "        X = df.drop([target], axis=1) # Using all column except for the last column as X\n",
        "        Y = df[target] # Selecting the last column as Y\n",
        "\n",
        "    plot(df,Y)\n",
        "\n",
        "    if model=='Logistic Regression':\n",
        "        model= LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=10000,multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "    elif model=='Random Forest Regressor':\n",
        "        model=RandomForestRegressor()\n",
        "    elif model=='Linear Regression​':\n",
        "        model= LinearRegression()\n",
        "    elif model=='Decision Tree Regressor​':\n",
        "        model= DecisionTreeRegressor()\n",
        "    elif model=='Support Vector Regression':\n",
        "        model= SVR(kernel='linear')\n",
        "    elif model=='RandomForestClassifier':\n",
        "        model=RandomForestClassifier()\n",
        "    else:\n",
        "        model=  OneVsRestClassifier(LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=10000,multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None))\n",
        "\n",
        "\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=0)\n",
        "    st.subheader('*Quality of Training and Testing (QoT) Toolkit*')\n",
        "    st.markdown('**1.2. Data splits**')\n",
        "    st.write('Training set')\n",
        "    st.info(X_train.shape)\n",
        "    st.write('Test set')\n",
        "    st.info(X_test.shape)\n",
        "\n",
        "    st.markdown('**1.3. Variable details**:')\n",
        "    st.write('X variable')\n",
        "    st.info(list(X.columns))\n",
        "    st.write('Y variable')\n",
        "    st.info(Y.name)\n",
        "\n",
        "\n",
        "    model.fit(X_train, Y_train)\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    thresh ={}\n",
        "    roc_auc={}\n",
        "    n_class = len(Y.unique())\n",
        "    st.subheader('2. Model Performance')\n",
        "    st.markdown('**Feature importance**')\n",
        "    name=type(model).__name__\n",
        "    st.write(name)\n",
        "\n",
        "    if name=='LogisticRegression' or name=='SVR'or name=='OneVsRestClassifier':\n",
        "        st.info(model.coef_[0])\n",
        "        col_sorted_by_importance=model.coef_[0].argsort()\n",
        "        feat_imp=pd.DataFrame({\n",
        "        'cols':X.columns[col_sorted_by_importance],\n",
        "        'imps':model.coef_[0][col_sorted_by_importance]\n",
        "        })\n",
        "    elif name=='DecisionTreeRegressor' or name=='RandomForestRegressor':\n",
        "        st.info(model.feature_importances_)\n",
        "        col_sorted_by_importance=model.feature_importances_.argsort()\n",
        "        feat_imp=pd.DataFrame({\n",
        "        'cols':X.columns[col_sorted_by_importance],\n",
        "        'imps':model.feature_importances_[col_sorted_by_importance]\n",
        "        })\n",
        "    else:\n",
        "        st.info(model.coef_)\n",
        "        col_sorted_by_importance=model.coef_.argsort()\n",
        "        feat_imp=pd.DataFrame({\n",
        "        'cols':X.columns[col_sorted_by_importance],\n",
        "        'imps':model.coef_[col_sorted_by_importance]\n",
        "        })\n",
        "\n",
        "    #Axis to color\n",
        "    color=\"imps\",\n",
        "    fig = px.bar(\n",
        "        feat_imp,\n",
        "        x = \"imps\",\n",
        "        y = \"cols\",\n",
        "        title = \"Feauture importance\",\n",
        "        color=\"imps\",\n",
        "        orientation = 'h'\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig)\n",
        "    st.markdown('**2. Accuracy**')\n",
        "    pred = model.predict(X_test)\n",
        "    #st.write(pred)\n",
        "    #st.write(Y_test)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax1 = sns.distplot(Y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
        "    sns.distplot(pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
        "    fig.legend(labels=['Actual','Predicted'])\n",
        "    st.pyplot(fig)\n",
        "    acc=0\n",
        "\n",
        "\n",
        "\n",
        "    if (name=='LogisticRegression'or name=='OneVsRestClassifier'):\n",
        "       acc=accuracy_score(pred, Y_test)*100\n",
        "    else :\n",
        "    # Performance metrics\n",
        "        errors = abs(pred - Y_test)\n",
        "        # Calculate mean absolute percentage error (MAPE)\n",
        "        mape = 100 * (errors / Y_test)\n",
        "        # Calculate and display accuracy\n",
        "        #acc = 100 - np.mean(mape)\n",
        "        acc = model.score(X_test, Y_test)*100\n",
        "\n",
        "    st.info(acc)\n",
        "    notguessed=100-acc\n",
        "    text= str(\"{:.2f}\".format(acc))+ '% Accuracy'\n",
        "    fig2 = go.Figure(data=[go.Pie( values=[acc,notguessed], pull=[0, 0.2],marker_colors=['blue','#0e1117'], textinfo='none')],layout =go.Layout( {\"showlegend\": False}))\n",
        "    fig2.update_traces(hole=.8, hoverinfo=\"percent\")\n",
        "    fig2.add_annotation(x= 0.5, y = 0.5,\n",
        "                    text = text,\n",
        "                    font = dict(size=20,family='Verdana',\n",
        "                                color='white'),\n",
        "                    showarrow = False)\n",
        "    st.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    st.markdown('**2.1. Training set**')\n",
        "    Y_pred_train = model.predict(X_train)\n",
        "\n",
        "\n",
        "    st.write('Coefficient of determination ($R^2$):')\n",
        "    st.info( r2_score(Y_train, Y_pred_train) )\n",
        "\n",
        "    st.write('Error (MSE or MAE):')\n",
        "    st.info( mean_squared_error(Y_train, Y_pred_train) )\n",
        "\n",
        "    st.markdown('**2.2. Test set**')\n",
        "    Y_pred_test = model.predict(X_test)\n",
        "    st.write('Coefficient of determination ($R^2$):')\n",
        "    st.info( r2_score(Y_test, Y_pred_test) )\n",
        "\n",
        "    st.write('Error (MSE or MAE):')\n",
        "    st.info( mean_squared_error(Y_test, Y_pred_test) )\n",
        "\n",
        "    if name=='LogisticRegression' or name=='OneVsRestClassifier':\n",
        "        cl=classification_report(Y_test, pred)\n",
        "        cm=confusion_matrix(Y_test, pred)\n",
        "        fig6=plt.figure(figsize=(12, 6))\n",
        "        ax2=sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "        plt.ylabel('Actual label');\n",
        "        plt.xlabel('Predicted label');\n",
        "        all_sample_title = 'Accuracy Score:{:.2f}'.format(acc)\n",
        "        plt.title(all_sample_title)\n",
        "        col1, col2 = st.columns(2)\n",
        "        col1.subheader(\"Classification report \")\n",
        "        col1.text(cl)\n",
        "        col2.subheader(\"Confusion Matrix\")\n",
        "        col2.write(fig6)\n",
        "        pred_prob = model.predict_proba(X_test)\n",
        "        from random import randint\n",
        "        colors = []\n",
        "        precision={}\n",
        "        recall={}\n",
        "        for i in range(10):\n",
        "            colors.append('#%06X' % randint(0, 0xFFFFFF))\n",
        "        for i in range(n_class):\n",
        "            fpr[i], tpr[i], thresh[i] = roc_curve(Y_test, pred_prob[:,i], pos_label=i)\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        for x in range(n_class):\n",
        "            precision[x], recall[x], _ = precision_recall_curve(Y_test,pred_prob[:,x], pos_label=x)\n",
        "\n",
        "        fig7=plt.figure(figsize=(12, 6))\n",
        "        for y in range(n_class):\n",
        "            plt.plot(fpr[y], tpr[y], linestyle='--',color=colors[y], label= 'Class:{0}'.format(y))\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive rate')\n",
        "        plt.legend(loc='best')\n",
        "\n",
        "        #plt.show()\n",
        "        #plt.show()\n",
        "        #precision, recall, _ = metrics.precision_recall_curve(Y_test, pred,pos_label=1)\n",
        "        #disp = metrics.PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "        #disp.plot()\n",
        "    # plt.show()\n",
        "\n",
        "        col3, col4 = st.columns(2)\n",
        "        col3.subheader(\"ROC Curve Plot for all classes\")\n",
        "\n",
        "        col3.pyplot( fig7)\n",
        "\n",
        "        col4.subheader(\"ROC Curve Plot for selected class\")\n",
        "\n",
        "        sel = col4.selectbox('Select class:',Y.unique())\n",
        "        col4.pyplot(Roc_curve(fpr, tpr, Y,colors,sel))\n",
        "        fig10=plt.figure(figsize=(12, 6))\n",
        "        for z in range(n_class):\n",
        "            plt.plot(recall[z], precision[z], lw=2, label='Class {0}'.format(z))\n",
        "\n",
        "        plt.xlabel(\"recall\")\n",
        "        plt.ylabel(\"precision\")\n",
        "        plt.legend(loc=\"best\")\n",
        "        plt.title(\"precision vs. recall curve\")\n",
        "        #plt.show()\n",
        "\n",
        "        st.header(\"PR AUC Plot\")\n",
        "\n",
        "        st.pyplot( fig10)\n",
        "\n",
        "    st.subheader('3. Model Parameters')\n",
        "    st.write(model.get_params())\n",
        "\n",
        "    st.subheader('*Explainable AI*')\n",
        "    #st.header('')\n",
        "    with st.expander(\"Feature Contribution to Model Output\"):\n",
        "        Shap(model,X_test,X_train,Y)\n",
        "    with st.expander(\"White Box Model\"):\n",
        "        Lime(X_train,Y_test,X_test,model)\n",
        "    with st.expander(\"Black Box Model Inspector\"):\n",
        "        if name=='LogisticRegression' or name=='OneVsRestClassifier':\n",
        "            perm = PermutationImportance(model, scoring = 'accuracy' ,random_state=101).fit(X_test, Y_test)\n",
        "\n",
        "        #show_weights(perm, feature_names = list(X_test.columns))\n",
        "\n",
        "        background = \"<style>:root {background-color: white;}</style>\"\n",
        "        if name=='LogisticRegression' or name=='OneVsRestClassifier':\n",
        "            html_object =show_weights(perm,feature_names=list(X_test.columns),target_names=Y_test)\n",
        "        else:\n",
        "            html_object =show_weights(model, feature_names=list(X_test.columns),target_names=Y_test)\n",
        "        raw_html = html_object._repr_html_()\n",
        "        components.html(background+raw_html,height=300,scrolling=True)\n",
        "        #with st.container():\n",
        "        if name=='LogisticRegression' or name=='OneVsRestClassifier':\n",
        "            html_object=show_prediction(model,X_test.iloc[0], feature_names=list(X_test.columns),target_names=Y.unique, show_feature_values=True)\n",
        "        else:\n",
        "            html_object=show_prediction(model, X_test.iloc[0], feature_names=list(X_test.columns),target_names=Y.unique, show_feature_values=True)\n",
        "        raw_html = html_object._repr_html_()\n",
        "        components.html(background+raw_html,height=300,scrolling=True)\n",
        "\n",
        "        html_object=eli5.explain_weights(model)\n",
        "\n",
        "        raw_html = html_object._repr_html_()\n",
        "        components.html(background+raw_html,height=300,scrolling=True)\n",
        "        html_object=eli5.explain_prediction(model, X.head(1))\n",
        "        raw_html = html_object._repr_html_()\n",
        "        components.html(background+raw_html,height=300,scrolling=True)\n",
        "\n",
        "#Scatterplot(df, Y)\n",
        "def Lime(X_train,y_test,X_test,model):\n",
        "    explainer = lime.lime_tabular.LimeTabularExplainer(np.array(X_train),mode=\"regression\", feature_names=list(X_train.columns), class_names=y_test, discretize_continuous=True)\n",
        "    # The Explainer Instance\n",
        "    idx = random.randint(1, len(X_test))\n",
        "    exp = explainer.explain_instance(X_test.iloc[3], model.predict, top_labels=1)\n",
        "    #html=exp.as_pyplot_figure()\n",
        "    exp.show_in_notebook(show_table=True)\n",
        "    html = exp.as_html()\n",
        "    background = \"<style>:root {background-color: white;}</style>\"\n",
        "    #components.html(yellow_background + html_content)\n",
        "    components.html(background+html, height=300,scrolling=True)\n",
        "    st.write(exp.as_list())\n",
        "    #st.title(\"Newsgroup Classifier\")\n",
        "    #st.write(f\"Document id = {idx}\")\n",
        "    #st.write(f\"Probability(christian) = {c.predict_proba([newsgroups_test.data[idx]])[0,1]}\")\n",
        "    #st.write(f\"True class:  {class_names[newsgroups_test.target[idx]]}\")\n",
        "    #exp.as_pyplot_figure()\n",
        "    #st.pyplot()\n",
        "    #plt.clf()\n",
        "    #st.markdown(exp.as_html(), unsafe_allow_html=True)\n",
        "\n",
        "def Scatterplot(df,target):\n",
        "    selected_x_var = st.selectbox('What do you want the x variable to be?', df.columns)\n",
        "    selected_y_var = st.selectbox('What about the y?', df.columns)\n",
        "    fig5 = px.scatter(df, x = df[selected_x_var], y = df[selected_y_var], color=target)\n",
        "    st.plotly_chart(fig5)\n",
        "\n",
        "def Shap(model,X_test,X_train,Y):\n",
        "    shap.initjs()\n",
        "    st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "    name=type(model).__name__\n",
        "\n",
        "    if name=='LogisticRegression' or name=='OneVsRestClassifier':\n",
        "        explainer = shap.KernelExplainer(model.predict_proba, X_train, feature_names=X_train.columns)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "        plt.title('Feature importance based on SHAP values')\n",
        "        fig11=plt.figure(figsize=(12, 6))\n",
        "        shap.summary_plot(shap_values,X_test,feature_names=X_train.columns)\n",
        "        st.pyplot (fig11)\n",
        "        st.write('---')\n",
        "\n",
        "        unique=Y.unique()\n",
        "        unique\n",
        "        for ind in range(len(unique)):\n",
        "            st.subheader('Class -{0}'.format(unique[ind]))\n",
        "            st_shap(shap.force_plot(explainer.expected_value[ind], shap_values[ind], X_test,feature_names=X_train.columns),500)\n",
        "            st.write('---')\n",
        "\n",
        "        for ind in range(len(unique)):\n",
        "            st.subheader('Class -{0}'.format(unique[ind]))\n",
        "            fig12=plt.figure(figsize=(12, 6))\n",
        "            shap.summary_plot(shap_values[ind],X_test,feature_names=X_train.columns,class_names=unique)\n",
        "            st.pyplot(fig12)\n",
        "            st.write('---')\n",
        "\n",
        "        for i in range(len(unique)):\n",
        "            ind = i\n",
        "            st.write(X_test.iloc[ind])\n",
        "            #st.write(explainer.expected_value[ind])\n",
        "            shap_display=shap.force_plot(explainer.expected_value[ind],shap_values[ind][0],X_test.iloc[ind],feature_names=X_train.columns)\n",
        "            st_shap(shap_display,150)\n",
        "            st.write('---')\n",
        "    else:\n",
        "        rf_explainer = shap.KernelExplainer(model.predict,X_test, feature_names=X_test.columns)\n",
        "        shap_values=rf_explainer.shap_values(X_test)\n",
        "        plt.title('Feature importance based on SHAP values')\n",
        "        fig20=plt.figure()\n",
        "        shap.summary_plot(shap_values, X_test)\n",
        "        #fig20.savefig(\"/summary_plot1.png\", bbox_inches='tight', dpi=600)\n",
        "        st.pyplot (fig20)\n",
        "        st.write('---')\n",
        "        st.write(X_test.iloc[10,:])\n",
        "\n",
        "        st_shap(shap.force_plot(rf_explainer.expected_value, shap_values[10,:], X_test.iloc[10,:]))\n",
        "\n",
        "        st.write('---')\n",
        "        st_shap(shap.force_plot(rf_explainer.expected_value, shap_values, X_test),500)\n",
        "        st.write('---')\n",
        "'''''\n",
        "'            explainer = shap.TreeExplainer(model)\n",
        "            shap_values = explainer.shap_values(X_train, approximate=False, check_additivity=False)\n",
        "            plt.title('Feature importance based on SHAP values')\n",
        "            fig20=plt.figure(figsize=(12, 6))\n",
        "            shap.summary_plot(shap_values, X_train)\n",
        "            st.pyplot (fig20)\n",
        "            st.write('---')'\n",
        "'''''\n",
        "\n",
        "def Roc_curve(fpr,tpr,Y,colors,sel):\n",
        "    fig8=plt.figure(figsize=(12, 6))\n",
        "    #sel = st.selectbox('Select class:',Y.unique())\n",
        "    plt.plot(fpr[sel], tpr[sel], linestyle='--',color='red', label= 'Class:{0}'.format(sel))\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive rate')\n",
        "    plt.legend(loc='best')\n",
        "    return fig8"
      ]
    }
  ]
}